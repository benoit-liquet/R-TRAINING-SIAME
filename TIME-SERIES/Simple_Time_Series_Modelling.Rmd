---
title: 'Time Series: a simple example'
author: "Benoit Liquet from RPubs"
date: "November 3, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
Here I analyse the R dataset of monthly totals of international airline passengers between 1949 to 1960 and apply a simple model to forecast 3-point estimates for 1961’s monthly totals. ARMA/ARIMA models will not be considered in this analysis.


## Load Data & Plot
Loading dataset AirPassengers into R’s workspace and assigning it to AP (for convenience):

```{r data}
data("AirPassengers")
AP <- AirPassengers
```
Time-series plot:

```{r plot}
plot(AP, ylab="Passengers (1000s)", type="o", pch =20)
```


Seasonality appears to increase with the general trend suggesting a multiplicative model rather than an additive model, i.e:

$$Y(t)=T(t)∗S(t)∗e(t)$$

where,
- $Y(t)$ is the number of passengers at time t
- $T(t)$ is the trend component at time t
- $S(t)$ is the seasonal component at time t
- $e(t)$ is the random error component at time t

## Decomposing the Data
Decomposing the data into its trend, seasonal, and random error components will give some idea how these components relate to the observed dataset.


```{r decompose}
AP.decompM <- decompose(AP, type = "multiplicative")
plot(AP.decompM)
```

## Model Fitting

### Trend Component

Inspecting the trend component in the decomposition plot suggests that the relationship is linear, thus fitting a linear model:

```{r trend}
t <- seq(1, 144, 1)
modelTrend <- lm(formula = AP.decompM$trend ~ t)
predT <- predict.lm(modelTrend, newdata = data.frame(t))

plot(AP.decompM$trend[7:138] ~ t[7:138], ylab="T(t)", xlab="t",
     type="p", pch=20, main = "Trend Component: Modelled vs Observed")
lines(predT, col="red")
```

```{r residual}
layout(matrix(c(1,2,3,4),2,2))
plot(modelTrend)
summary(modelTrend)
```

Therefore, the relationship between trend and time can be expressed as:
$$\widehat{T(t)}=2.666t+84.648$$
And so for 1961 (time 145 to 156 inc.), the trend component (T) is:

```{r estimate_trend}
Data1961 <- data.frame("T" = 2.667*seq(145, 156, 1) + 84.648, S=rep(0,12), e=rep(0,12),
                       row.names = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))
Data1961
```

## Seasonal Component
Inspecting the seasonal (S) component of the decomposition reveals:

```{r seasaon}
AP.decompM$seasonal
```

Thus the seasonal (S) component to the new 1961 dataset is:

```{r estimate_season}
Data1961$S <- unique(AP.decompM$seasonal)
Data1961
```

## Random Error Component
Ploting the density estimation of the random error (e) component of the decomposition shows an approximate normal distribution:

```{r error}
plot(density(AP.decompM$random[7:138]),
             main="Random Error") #Values 1:6 & 139:44 are NA
```

Bootstrapping the mean statistic of the random error would produce an accurate approximation of the population mean of the randon error. However, I believe this is too costly for the reward it gives and thus I shall assume the population mean of the random error is:

```{r mean}
mean(AP.decompM$random[7:138])
```

which is 1.

Thus the decomposed dataset for 1961 is:
```{r e}
Data1961$e <- 1
Data1961
```

## Predictions (1961)

For my 1961 3-point estimates for each month, I assume that all variation is due to the random error (for simplicity) and so taking the standard deviation of the random error distribution gives:

```{r standard}
sd_error <- sd(AP.decompM$random[7:138])
sd_error
```

And so the 3-point esitmates (Realistic, Optimistic, Pessimistic) for the predictions is simply the expected prediction (T∗S∗e), and 95$\%$ CI interval either way using the standard deviation of the random error (95$\%$ CI = 1.95$\times$sd


```{r interval_pred}
Data1961$R <- Data1961$T * Data1961$S * Data1961$e                  #Realistic Estimation
Data1961$O <- Data1961$T * Data1961$S * (Data1961$e+1.95*sd_error)  #Optimistic Estimation
Data1961$P <- Data1961$T * Data1961$S * (Data1961$e-1.95*sd_error)  #Pessimistic Estimation
Data1961
```

Graphically:

```{r graph}
xr = c(1,156)
plot(AP.decompM$x, xlim=xr, ylab = "Passengers (100s)", xlab = "Month")
lines(data.frame(AP.decompM$x))
lines(Data1961$R, x=seq(145,156,1), col="blue")
lines(Data1961$O, x=seq(145,156,1), col="green")
lines(Data1961$P, x=seq(145,156,1), col="red")
```

## Conclusions
The realistic estimations for 1961 are less than 1960 data. This is because the linear regression modelling the trend component under-estimates the trend component towards the end of the observable dataset (see figure above). A piecewise regression or swicting to an ARMA/ARIMA model would give better predictions.

## Further Considerations
ARMA/ARIMA model. Model validation (in this analysis, test set = training set and thus no model validation has taken place).


